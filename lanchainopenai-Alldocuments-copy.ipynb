{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Setting up the Envirnoment variables and installing dependencies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1706826111775
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://optimo-openai-sbx.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"88ea0ee6c81f44dea5df38a985512575\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.0.5)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (0.1.17)\n",
            "Requirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (1.21.6)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (1.10.0)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (0.5.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
            "Requirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.10.8)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.2)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.85)\n",
            "Requirement already satisfied: anyio<5,>=3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (3.6.2)\n",
            "Requirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.5.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1.16->langchain-openai) (3.4)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.1.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (2.0.25)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.0.16)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.1.17)\n",
            "Requirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.21.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.10.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.0.85)\n",
            "Requirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (4.9.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.6.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (4.0.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.4.3; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pypdf) (4.9.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-openai in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.0.5)\n",
            "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (0.5.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (1.10.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (1.21.6)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-openai) (0.1.17)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.5.5)\n",
            "Requirement already satisfied: requests>=2.26.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.8.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.6.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.10.8)\n",
            "Requirement already satisfied: sniffio in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (23.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (8.2.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (0.0.85)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain-openai) (6.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken<0.6.0,>=0.5.2->langchain-openai) (1.26.16)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken<0.6.0,>=0.5.2->langchain-openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken<0.6.0,>=0.5.2->langchain-openai) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.26.0->tiktoken<0.6.0,>=0.5.2->langchain-openai) (3.1.0)\n",
            "Requirement already satisfied: httpcore==1.* in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain-openai) (2.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Instantiating the GPT35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1706826131581
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import langchain_openai\n",
        "from langchain_openai import AzureChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1706826131886
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = AzureChatOpenAI(\n",
        "    openai_api_version=\"2023-05-15\",\n",
        "    azure_deployment=\"GPT3516K\",    \n",
        "       \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1706826132232
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AzureChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7efdf4fabdc0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7efdf4fbd340>, openai_api_key='88ea0ee6c81f44dea5df38a985512575', openai_proxy='', azure_endpoint='https://optimo-openai-sbx.openai.azure.com/', deployment_name='GPT3516K', openai_api_version='2023-05-15', openai_api_type='azure')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1706826132556
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.schema import HumanMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### testing Model Query and Respone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1706826132910
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "message = HumanMessage(\n",
        "    content=\"Capital of India.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1706826133223
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of India is New Delhi.')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model([message])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1706826133521
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import getpass\n",
        "# import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1706826133736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import langchain_openai\n",
        "# from langchain_openai import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1706826134043
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "# embeddings = AzureOpenAIEmbeddings(\n",
        "#     azure_deployment=\"\",\n",
        "#     openai_api_version=\"2023-05-15\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1706826134352
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# text = \"this is a test document\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1706826134614
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# query_result = embeddings.embed_query(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1706826134847
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# embeddings =  langchain_openai.AzureOpenAIEmbeddings()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#https://python.langchain.com/docs/integrations/text_embedding/openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1706826135096
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1706826135356
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# import langchain_openai\n",
        "# from langchain_openai import OpenAIEmbeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1706826135587
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings(\n",
        "#     deployment=\"text-embedding-ada-002-new\",\n",
        "#     model=\"text-embedding-ada-002-new\",\n",
        "#     openai_api_base=\"https://your-endpoint.openai.azure.com/\",\n",
        "#     openai_api_type=\"azure\",\n",
        "# )\n",
        "# text = \"This is a test query.\"\n",
        "# query_result = embeddings.embed_query(text)[*Deprecated*] OpenAI embedding models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1706826135807
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://optimo-openai-sbx.openai.azure.com/\"\n",
        "# os.environ[\"AZURE_OPENAI_API_KEY\"] = \"88ea0ee6c81f44dea5df38a985512575\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.0.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (6.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (0.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (0.1.17)\n",
            "Requirement already satisfied: numpy<2,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (1.21.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (2.0.25)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (8.2.2)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (0.0.85)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain_community) (3.8.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (1.26.16)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain_community) (23.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain_community) (1.33)\n",
            "Requirement already satisfied: anyio<5,>=3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain_community) (3.6.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from langchain-core<0.2,>=0.1.16->langchain_community) (1.10.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.16->langchain_community) (2.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain_community) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Creating instance of AzureEmbedddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1706826140930
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "\n",
        "openai_embedding = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", deployment=\"text-embedding-ada-002-new\", openai_api_key=\"88ea0ee6c81f44dea5df38a985512575\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1706826141344
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "text = \"This is a test query.\"\n",
        "query_result = openai_embedding.embed_query(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1706826141675
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# # from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "# import langchain_community\n",
        "# embeddings = langchain_community.embeddings.openai.OpenAIEmbeddings(\n",
        "#     deployment=\"text-embedding-ada-002-new\",\n",
        "#     model=\"text-embedding-ada-002\",\n",
        "#     openai_api_base=\"https://optimo-openai-sbx.openai.azure.com/\",\n",
        "#     openai_api_type=\"azure\",\n",
        "#     openai_api_key=\"88ea0ee6c81f44dea5df38a985512575\"\n",
        "# )\n",
        "# text = \"This is a test query.\"\n",
        "# query_result = embeddings.embed_query(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1706826141924
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# # from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings(\n",
        "#     deployment=\"text-embedding-ada-002-new\",\n",
        "#     model=\"text-embedding-ada-002-new\",\n",
        "#     openai_api_key=\"88ea0ee6c81f44dea5df38a985512575\"\n",
        "# )\n",
        "# text = \"This is a test query.\"\n",
        "# query_result = embeddings.embed_query(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1706826142146
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain.document_loaders import PyPDFDirectoryLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1706826142623
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1706826143663
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1706826146822
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Users/sguthula/.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Reading a document and creating Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1706826147758
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "directory_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Documents\"\n",
        "loader_docx = DirectoryLoader(directory_path, glob=\"**/*.docx\", loader_cls=Docx2txtLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1706826148853
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_docx=loader_docx.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1706826149628
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "directory_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula\"\n",
        "loader_pdf = DirectoryLoader(directory_path, glob=\"**/*.pdf\", loader_cls=PyPDFLoader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1706826152332
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_pdf = loader_pdf.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1706826152546
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pages = data_docx+data_pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1706826152924
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "# Create the TextLoader object using the file path\n",
        "path= \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula\"\n",
        "loader = DirectoryLoader(path, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
        "#loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1706826154691
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "# loader = PyPDFLoader(\"/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Change_request.pdf\")\n",
        "# # docs = loader.load()\n",
        "# pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "gather": {
          "logged": 1706826155675
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# from langchain_community.vectorstores import FAISS\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# faiss_index = FAISS.from_documents(pages, openai_embedding())\n",
        " # docs = faiss_index.similarity_search(\"How will the community be engaged?\", k=2)\n",
        " # for doc in docs:\n",
        " #     print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### sett up Meta FAISS as Vector DB Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1706826157875
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "vectorstore = FAISS.from_documents(pages, openai_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1706826158140
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "db_retreiver = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Retreiving the simlar chinks available in VectorDB based on input search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1706826158658
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Page 1 of 8', metadata={'source': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Documents/StatementWork.pdf', 'page': 0}),\n",
              " Document(page_content='Page 8 of 8', metadata={'source': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Documents/StatementWork.pdf', 'page': 7}),\n",
              " Document(page_content='Page 2 of 8', metadata={'source': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Documents/StatementWork.pdf', 'page': 1}),\n",
              " Document(page_content='Page 3 of 8', metadata={'source': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/sguthula1/code/Users/sguthula/Documents/StatementWork.pdf', 'page': 2})]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Retreiving the relevant chucks for the query\n",
        "db_retreiver.get_relevant_documents(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Creating a conversational chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1706826160312
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_community.llms import OpenAI\n",
        "\n",
        "conversation = ConversationChain(llm=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1706826160734
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "gather": {
          "logged": 1706826161639
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "memory = ConversationBufferMemory(\n",
        "        memory_key='chat_history', return_messages=True)\n",
        "\n",
        "conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=model,\n",
        "        retriever=vectorstore.as_retriever(),\n",
        "        memory=memory,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "gather": {
          "logged": 1706826163620
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# chat_history = []\n",
        "\n",
        "# # query = \"buero  of labour experience year for swathi guthula\"\n",
        "# query = \" swathi guthula highest degree of education\"\n",
        "# result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "# print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "gather": {
          "logged": 1706826163992
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# chat_history = []\n",
        "\n",
        "# query = \"who is Oliver the owl in the story\"\n",
        "\n",
        "# result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "# print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from InputQuery import input_Query\n",
        "# query1 = input_Query()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "gather": {
          "logged": 1706826165321
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# chat_history = []\n",
        "# #query = \"where Steve job when to  5th grade?\"\n",
        "# query = query1\n",
        "# result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "# print(result['answer'])\n",
        "\n",
        "# response = result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def response_output():\n",
        "#     return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# response_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# class llm_query:\n",
        "#     def response_output():\n",
        "#         return response "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chmod: cannot access '/tmp/ngrok/ngrok': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod +x /tmp/ngrok/ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install flask-ngrok\n",
        "\n",
        "# from flask import Flask, request, jsonify\n",
        "# from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# app = Flask(__name__)\n",
        "# run_with_ngrok(app)  # Start ngrok when app is run\n",
        "\n",
        "# @app.route('/api', methods=['POST'])\n",
        "# def api_endpoint():\n",
        "#     data = request.get_json()  # Get the JSON data from the request\n",
        "#     input_data = data.get('input', None)  # Get the 'input' field from the JSON data\n",
        "\n",
        "#     if input_data is None:\n",
        "#         return jsonify({'error': 'No input field in the request data'}), 400  # Return error if no 'input' field\n",
        "\n",
        "#     # Process the input in some way\n",
        "#     # For this example, we'll just return the input data in the response\n",
        "#     response_data = {'response': input_data}\n",
        "\n",
        "#     return jsonify(response_data), 200\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from flask import Flask, request, jsonify\n",
        "\n",
        "# app = Flask(__name__)\n",
        "\n",
        "# @app.route('/api', methods=['POST'])\n",
        "# def api_endpoint():\n",
        "#     data = request.get_json()  # Get the JSON data from the request\n",
        "#     input_data = data.get('input', None)  # Get the 'input' field from the JSON data\n",
        "\n",
        "#     if input_data is None:\n",
        "#         return jsonify({'error': 'No input field in the request data'}), 400  # Return error if no 'input' field\n",
        "\n",
        "#     # Process the input in some way\n",
        "#     # For this example, we'll just return the input data in the response\n",
        "#     query = input_data\n",
        "#     result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "#     response_data = {'response': result}\n",
        "\n",
        "#     return jsonify(response_data), 200\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     app.run(debug=True, port=8080)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from flask import Flask, request  # import main Flask class and request object\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "app1 = Flask(__name__)  # create the Flask app\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app1.route('/status', methods=['GET'])\n",
        "def api_endpoint():\n",
        "    return \"Alive!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonify in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install jsonify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "import jsonify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app1.route('/predict', methods=['GET'])\n",
        "def predict():\n",
        "    query = \"Who is Swathi\"\n",
        "    print(\"QUERY\", query)\n",
        "    result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "    response_data = {'response': result['answer']}\n",
        "    return response_data, 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "@app1.route('/predictquery', methods=['POST'])\n",
        "def predictquery():\n",
        "    data = request.get_json()  # Get the JSON data from the request\n",
        "    print(data)\n",
        "    # input_data = data.get('input', None)  # Get the 'input' field from the JSON data\n",
        "    # if input_data is None:\n",
        "    #     return jsonify({'error': 'No input field in the request data'}), 400  # Return error if no 'input' field\n",
        "\n",
        "    # print(\"input_date\", input_data)\n",
        "    # Process the input in some way\n",
        "    # For this example, we'll just return the input data in the response\n",
        "    query = data\n",
        "    print(\"QUERY\", query)\n",
        "    result = conversation_chain({\"question\": query, \"chat_history\": chat_history})\n",
        "    response_data = {'response': result['answer']}\n",
        "    return response_data, 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:8080\n",
            "Press CTRL+C to quit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QUERY Who is Swathi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "127.0.0.1 - - [07/Feb/2024 01:45:53] \"GET /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Which college swathi studied\n",
            "QUERY Which college swathi studied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [07/Feb/2024 01:45:54] \"POST /predictquery HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QUERY Who is Swathi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [07/Feb/2024 01:47:48] \"GET /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "period of performance for CISA\n",
            "QUERY period of performance for CISA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [07/Feb/2024 01:47:50] \"POST /predictquery HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "app1.run(port=8080)  # run app in debug mode on port 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
